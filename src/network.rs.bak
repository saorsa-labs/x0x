//! Network transport layer for x0x.
//!
//! This module provides x0x-specific wrappers around ant-quic's
//! P2P node, configured for optimal gossip network participation.

use crate::error::{NetworkError, Result};
use ant_quic::quic_node::{QuicP2PNode, QuicNodeConfig};
use ant_quic::auth::AuthConfig;
use ant_quic::nat_traversal_api::EndpointRole;
use serde::{Deserialize, Serialize};
use std::net::SocketAddr;
use std::path::PathBuf;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::broadcast;

/// Default port for x0x nodes (when specified).
pub const DEFAULT_PORT: u16 = 12000;

/// Default health/metrics port.
pub const DEFAULT_METRICS_PORT: u16 = 12600;

/// Default maximum connections.
pub const DEFAULT_MAX_CONNECTIONS: u32 = 100;

/// Default connection timeout.
pub const DEFAULT_CONNECTION_TIMEOUT: Duration = Duration::from_secs(30);

/// Default stats collection interval.
pub const DEFAULT_STATS_INTERVAL: Duration = Duration::from_secs(60);

/// x0x network node configuration.
///
/// This struct wraps ant-quic's `QuicNodeConfig` with x0x-specific
/// defaults optimized for gossip network participation.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NetworkConfig {
    /// The role this node plays in the network.
    #[serde(default)]
    pub role: NodeRole,

    /// Socket address to bind to. If None, a random port is chosen.
    #[serde(default)]
    pub bind_addr: Option<SocketAddr>,

    /// Bootstrap nodes to connect to on startup.
    #[serde(default)]
    pub bootstrap_nodes: Vec<SocketAddr>,

    /// Maximum number of concurrent connections.
    #[serde(default = "default_max_connections")]
    pub max_connections: u32,

    /// Timeout for establishing connections.
    #[serde(default = "default_connection_timeout")]
    pub connection_timeout: Duration,

    /// Interval for collecting and reporting stats.
    #[serde(default = "default_stats_interval")]
    pub stats_interval: Duration,

    /// Enable coordinator functionality (for bootstrap nodes).
    #[serde(default)]
    pub enable_coordinator: bool,

    /// Path to the TLS private key file (if using TLS mode).
    #[serde(default)]
    pub tls_private_key_path: Option<PathBuf>,

    /// Path to persist peer cache.
    #[serde(default)]
    pub peer_cache_path: Option<PathBuf>,
}

fn default_max_connections() -> u32 {
    DEFAULT_MAX_CONNECTIONS
}

fn default_connection_timeout() -> Duration {
    DEFAULT_CONNECTION_TIMEOUT
}

fn default_stats_interval() -> Duration {
    DEFAULT_STATS_INTERVAL
}

impl Default for NetworkConfig {
    fn default() -> Self {
        Self {
            role: NodeRole::Client,
            bind_addr: None,
            bootstrap_nodes: Vec::new(),
            max_connections: DEFAULT_MAX_CONNECTIONS,
            connection_timeout: DEFAULT_CONNECTION_TIMEOUT,
            stats_interval: DEFAULT_STATS_INTERVAL,
            enable_coordinator: false,
            tls_private_key_path: None,
            peer_cache_path: None,
        }
    }
}

/// The role a node plays in the x0x network.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, Default)]
#[serde(rename_all = "snake_case")]
pub enum NodeRole {
    /// Regular client node that participates in gossip.
    #[default]
    Client,
    /// Bootstrap/coordinator node that helps other nodes connect.
    Bootstrap,
    /// Relay node for symmetric NAT traversal.
    Relay,
}

impl From<NodeRole> for EndpointRole {
    fn from(role: NodeRole) -> Self {
        match role {
            NodeRole::Client => EndpointRole::Client,
            NodeRole::Bootstrap => EndpointRole::Bootstrap,
            NodeRole::Relay => EndpointRole::Relay,
        }
    }
}

/// Statistics for the network node.
#[derive(Debug, Clone, Default)]
pub struct NetworkStats {
    /// Total number of connections established.
    pub total_connections: u64,
    /// Currently active connections.
    pub active_connections: u32,
    /// Total bytes sent.
    pub bytes_sent: u64,
    /// Total bytes received.
    pub bytes_received: u64,
    /// Number of peers in the local view.
    pub peer_count: usize,
}

/// The x0x network node.
///
/// This wraps ant-quic's `QuicP2PNode` with x0x-specific functionality
/// including event broadcasting, peer cache management, and graceful shutdown.
#[derive(Debug)]
pub struct NetworkNode {
    /// The underlying ant-quic node.
    inner: Arc<QuicP2PNode>,

    /// Configuration for this node.
    config: NetworkConfig,

    /// Sender for connection events.
    event_sender: broadcast::Sender<NetworkEvent>,

    /// Peer cache for bootstrap persistence.
    peer_cache: Option<PeerCache>,
}

impl NetworkNode {
    /// Create a new network node with the given configuration.
    ///
    /// # Arguments
    ///
    /// * `config` - Network configuration options.
    ///
    /// # Returns
    ///
    /// A new NetworkNode on success.
    ///
    /// # Errors
    ///
    /// Returns `NetworkError` if node creation fails.
    pub async fn new(config: NetworkConfig) -> Result<Self> {
        let auth_config = AuthConfig::default();

        let quic_config = QuicNodeConfig {
            role: config.role.into(),
            bootstrap_nodes: config.bootstrap_nodes.clone(),
            enable_coordinator: config.enable_coordinator,
            max_connections: config.max_connections,
            connection_timeout: config.connection_timeout,
            stats_interval: config.stats_interval,
            auth_config,
            bind_addr: config.bind_addr,
        };

        let inner = QuicP2PNode::new(quic_config)
            .await
            .map_err(|e| NetworkError::NodeCreation(e.to_string()))?;

        // Create event channel with large buffer for burst events.
        let (event_sender, _) = broadcast::channel(256);

        // Initialize peer cache if path provided.
        let peer_cache = if let Some(ref path) = config.peer_cache_path {
            Some(PeerCache::load_or_create(path).await?)
        } else {
            None
        };

        Ok(Self {
            inner: Arc::new(inner),
            config,
            event_sender,
            peer_cache,
        })
    }

    /// Get the underlying ant-quic node.
    ///
    /// # Returns
    ///
    /// A reference to the inner QuicP2PNode.
    pub fn inner(&self) -> &QuicP2PNode {
        &self.inner
    }

    /// Get the local socket address.
    ///
    /// # Returns
    ///
    /// The local address this node is bound to.
    pub fn local_addr(&self) -> SocketAddr {
        self.inner.local_addr()
    }

    /// Get the node's peer ID.
    ///
    /// # Returns
    ///
    /// This node's peer ID derived from its public key.
    pub fn peer_id(&self) -> [u8; 32] {
        self.inner.peer_id()
    }

    /// Subscribe to network events.
    ///
    /// # Returns
    ///
    /// A receiver that will receive network events.
    pub fn subscribe(&self) -> broadcast::Receiver<NetworkEvent> {
        self.event_sender.subscribe()
    }

    /// Get current network statistics.
    ///
    /// # Returns
    ///
    /// Network statistics for this node.
    pub async fn stats(&self) -> NetworkStats {
        let inner_stats = self.inner.stats().await;
        NetworkStats {
            total_connections: inner_stats.total_connections,
            active_connections: inner_stats.active_connections,
            bytes_sent: inner_stats.bytes_sent,
            bytes_received: inner_stats.bytes_received,
            peer_count: inner_stats.peer_count,
        }
    }

    /// Get the number of active connections.
    ///
    /// # Returns
    ///
    /// The number of currently connected peers.
    pub async fn connection_count(&self) -> usize {
        self.inner.connection_count().await
    }

    /// Add a peer to the cache.
    ///
    /// # Arguments
    ///
    /// * `peer_id` - The peer's ID.
    /// * `address` - The peer's socket address.
    pub async fn cache_peer(&mut self, peer_id: [u8; 32], address: SocketAddr) {
        if let Some(ref mut cache) = self.peer_cache {
            cache.add_peer(peer_id, address);
            if let Some(ref path) = self.config.peer_cache_path {
                let _ = cache.save(path).await;
            }
        }
    }

    /// Get cached peers for bootstrap.
    ///
    /// # Arguments
    ///
    /// * `count` - Maximum number of peers to return.
    ///
    /// # Returns
    ///
    /// A vector of cached peer addresses.
    pub fn cached_peers(&self, count: usize) -> Vec<SocketAddr> {
        self.peer_cache.as_ref().map(|c| c.select_peers(count)).unwrap_or_default()
    }

    /// Gracefully shutdown the node.
    ///
    /// This closes all connections and stops the node.
    pub async fn shutdown(&mut self) {
        // Save peer cache before shutdown.
        if let (Some(ref cache), Some(ref path)) = (&self.peer_cache, &self.config.peer_cache_path) {
            let _ = cache.save(path).await;
        }

        // Shutdown the inner node.
        self.inner.shutdown().await;
    }
}

/// Events emitted by the network node.
#[derive(Debug, Clone)]
pub enum NetworkEvent {
    /// A new peer connected.
    PeerConnected {
        /// The peer's ID.
        peer_id: [u8; 32],
        /// The peer's address.
        address: SocketAddr,
    },

    /// A peer disconnected.
    PeerDisconnected {
        /// The peer's ID.
        peer_id: [u8; 32],
    },

    /// NAT type was detected.
    NatTypeDetected {
        /// The detected NAT type.
        nat_type: String,
    },

    /// External address was discovered.
    ExternalAddressDiscovered {
        /// The discovered external address.
        address: SocketAddr,
    },

    /// Connection error occurred.
    ConnectionError {
        /// The peer ID if applicable.
        peer_id: Option<[u8; 32]>,
        /// The error message.
        error: String,
    },
}

/// In-memory peer cache for bootstrap persistence.
///
/// Uses epsilon-greedy algorithm for peer selection.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PeerCache {
    /// Cached peers with their addresses and success metrics.
    peers: Vec<CachedPeer>,
    /// Path to the cache file.
    #[serde(skip)]
    cache_path: PathBuf,
    /// Epsilon value for epsilon-greedy selection.
    epsilon: f64,
}

impl PeerCache {
    /// Load peer cache from disk, or create a new one.
    ///
    /// # Arguments
    ///
    /// * `path` - Path to the cache file.
    ///
    /// # Returns
    ///
    /// A new PeerCache, either loaded or created.
    pub async fn load_or_create(path: &PathBuf) -> Result<Self> {
        if let Some(parent) = path.parent() {
            if !parent.exists() {
                tokio::fs::create_dir_all(parent).await.map_err(|e| {
                    NetworkError::CacheError(e.to_string())
                })?;
            }
        }

        if path.exists() {
            let data = tokio::fs::read(path).await.map_err(|e| {
                NetworkError::CacheError(e.to_string())
            })?;
            let cache: PeerCache = bincode::deserialize(&data).map_err(|e| {
                NetworkError::CacheError(e.to_string())
            })?;
            return Ok(cache);
        }

        Ok(Self {
            peers: Vec::new(),
            cache_path: path.clone(),
            epsilon: 0.1, // 10% exploration rate
        })
    }

    /// Add a peer to the cache.
    ///
    /// # Arguments
    ///
    /// * `peer_id` - The peer's ID.
    /// * `address` - The peer's address.
    pub fn add_peer(&mut self, peer_id: [u8; 32], address: SocketAddr) {
        // Update existing peer or add new one.
        if let Some(existing) = self.peers.iter_mut().find(|p| p.peer_id == peer_id) {
            existing.address = address;
            existing.success_count += 1;
            existing.last_seen = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs();
        } else {
            self.peers.push(CachedPeer {
                peer_id,
                address,
                success_count: 1,
                attempt_count: 0,
                last_seen: std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_secs(),
                last_attempt: 0,
            });
        }
    }

    /// Select peers using epsilon-greedy algorithm.
    ///
    /// # Arguments
    ///
    /// * `count` - Number of peers to select.
    ///
    /// # Returns
    ///
    /// A vector of peer addresses.
    pub fn select_peers(&self, count: usize) -> Vec<SocketAddr> {
        if self.peers.is_empty() {
            return Vec::new();
        }

        let mut sorted_peers: Vec<_> = self.peers.iter().collect();

        // Sort by success rate (descending).
        sorted_peers.sort_by(|a, b| {
            let a_rate = a.success_count as f64 / (a.attempt_count.max(1) as f64);
            let b_rate = b.success_count as f64 / (b.attempt_count.max(1) as f64);
            b_rate.partial_cmp(&a_rate).unwrap_or(std::cmp::Ordering::Equal)
        });

        let exploit_count = ((count as f64) * (1.0 - self.epsilon)).floor() as usize;
        let explore_count = (count - exploit_count).min(self.peers.len() - exploit_count);

        let mut selected: Vec<SocketAddr> = sorted_peers[..exploit_count.min(count)]
            .iter()
            .map(|p| p.address)
            .collect();

        // Add random exploration peers.
        if explore_count > 0 && self.peers.len() > exploit_count {
            let explore_from: Vec<_> = sorted_peers[exploit_count..].to_vec();
            for _ in 0..explore_count {
                if let Some(random_peer) = explore_from.choose(&mut rand::thread_rng()) {
                    selected.push(random_peer.address);
                }
            }
        }

        selected
    }

    /// Save the peer cache to disk.
    ///
    /// # Arguments
    ///
    /// * `path` - Path to save to (overrides the original path).
    ///
    /// # Errors
    ///
    /// Returns an error if saving fails.
    pub async fn save(&self, path: &PathBuf) -> Result<()> {
        let data = bincode::serialize(self).map_err(|e| {
            NetworkError::CacheError(e.to_string())
        })?;
        tokio::fs::write(path, data).await.map_err(|e| {
            NetworkError::CacheError(e.to_string())
        })?;
        Ok(())
    }

    /// Get the number of cached peers.
    ///
    /// # Returns
    ///
    /// The number of peers in the cache.
    pub fn len(&self) -> usize {
        self.peers.len()
    }

    /// Check if the cache is empty.
    ///
    /// # Returns
    ///
    /// True if the cache has no peers.
    pub fn is_empty(&self) -> bool {
        self.peers.is_empty()
    }
}

/// A cached peer entry.
#[derive(Debug, Clone, Serialize, Deserialize)]
struct CachedPeer {
    /// The peer's ID.
    peer_id: [u8; 32],
    /// The peer's address.
    address: SocketAddr,
    /// Number of successful connections.
    success_count: u32,
    /// Number of connection attempts.
    attempt_count: u32,
    /// Timestamp of last successful connection.
    last_seen: u64,
    /// Timestamp of last connection attempt.
    last_attempt: u64,
}

#[cfg(test)]
mod tests {
    #![allow(clippy::unwrap_used)]

    use super::*;

    #[test]
    fn test_network_config_defaults() {
        let config = NetworkConfig::default();

        assert_eq!(config.role, NodeRole::Client);
        assert!(config.bind_addr.is_none());
        assert!(config.bootstrap_nodes.is_empty());
        assert_eq!(config.max_connections, DEFAULT_MAX_CONNECTIONS);
        assert_eq!(config.connection_timeout, DEFAULT_CONNECTION_TIMEOUT);
    }

    #[test]
    fn test_node_role_serialization() {
        let client = NodeRole::Client;
        let serialized = serde_json::to_string(&client).unwrap();
        assert!(serialized.contains("client"));

        let deserialized: NodeRole = serde_json::from_str(&serialized).unwrap();
        assert_eq!(deserialized, NodeRole::Client);
    }

    #[tokio::test]
    async fn test_peer_cache_add_and_select() {
        let mut cache = PeerCache {
            peers: Vec::new(),
            cache_path: PathBuf::from("/tmp/test_peer_cache.bin"),
            epsilon: 0.1,
        };

        // Add some peers.
        cache.add_peer([1; 32], "127.0.0.1:9000".parse().unwrap());
        cache.add_peer([2; 32], "127.0.0.1:9001".parse().unwrap());
        cache.add_peer([3; 32], "127.0.0.1:9002".parse().unwrap());

        // Select peers.
        let selected = cache.select_peers(2);
        assert_eq!(selected.len(), 2);
    }

    #[tokio::test]
    async fn test_peer_cache_persistence() {
        let temp_dir = tempfile::tempdir().unwrap();
        let cache_path = temp_dir.path().join("peer_cache.bin");

        {
            let mut cache = PeerCache {
                peers: Vec::new(),
                cache_path: cache_path.clone(),
                epsilon: 0.1,
            };

            cache.add_peer([1; 32], "127.0.0.1:9000".parse().unwrap());
            cache.save(&cache_path).await.unwrap();
        }

        // Load from disk.
        let loaded = PeerCache::load_or_create(&cache_path).await.unwrap();
        assert_eq!(loaded.len(), 1);
    }

    #[tokio::test]
    async fn test_network_stats_default() {
        let stats = NetworkStats::default();
        assert_eq!(stats.total_connections, 0);
        assert_eq!(stats.active_connections, 0);
        assert_eq!(stats.bytes_sent, 0);
        assert_eq!(stats.bytes_received, 0);
        assert_eq!(stats.peer_count, 0);
    }
}
